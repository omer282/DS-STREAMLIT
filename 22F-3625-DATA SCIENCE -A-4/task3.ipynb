{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaE31hscfbZW"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import joblib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import asyncio\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Define DNN class (must match Task 1 and Task 2 architectures)\n",
        "class AudioDNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(AudioDNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class DefectDNN(nn.Module):\n",
        "    def __init__(self, input_dim, n_labels):\n",
        "        super(DefectDNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, n_labels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Define MultiLabelPerceptron class (must match Task 2 definition)\n",
        "class MultiLabelPerceptron:\n",
        "    def __init__(self, n_features, n_labels, learning_rate=0.01):\n",
        "        self.weights = np.zeros((n_labels, n_features))\n",
        "        self.bias = np.zeros(n_labels)\n",
        "        self.lr = learning_rate\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = X @ self.weights.T + self.bias\n",
        "        return (scores > 0).astype(int)\n",
        "\n",
        "    def update(self, x, y_true):\n",
        "        y_pred = self.predict(x.reshape(1, -1))[0]\n",
        "        for label in range(len(y_true)):\n",
        "            if y_true[label] != y_pred[label]:\n",
        "                self.weights[label] += self.lr * (y_true[label] - y_pred[label]) * x\n",
        "                self.bias[label] += self.lr * (y_true[label] - y_pred[label])\n",
        "\n",
        "# Initialize event loop (workaround for RuntimeError)\n",
        "try:\n",
        "    loop = asyncio.get_event_loop()\n",
        "    if not loop.is_running():\n",
        "        asyncio.set_event_loop(asyncio.new_event_loop())\n",
        "except RuntimeError:\n",
        "    pass\n",
        "\n",
        "# Load pre-trained models and preprocessing objects\n",
        "try:\n",
        "    # Task 1 (Audio Models)\n",
        "    lr_audio_model = joblib.load(\"lr_audio_model.joblib\")\n",
        "    svm_audio_model = joblib.load(\"svm_audio_model.joblib\")\n",
        "    perceptron_audio_model = joblib.load(\"perceptron_audio_model.joblib\")\n",
        "    dnn_audio_model = AudioDNN(input_dim=3900)  # Match Task 1 input dimension (13 * 300)\n",
        "    dnn_audio_model.load_state_dict(torch.load(\"dnn_audio_model.pth\"))\n",
        "    dnn_audio_model.eval()\n",
        "    audio_scaler = joblib.load(\"audio_scaler.joblib\")\n",
        "\n",
        "    # Task 2 (Defect Models)\n",
        "    lr_defect_model = joblib.load(\"lr_defect_model.joblib\")\n",
        "    svm_defect_model = joblib.load(\"svm_defect_model.joblib\")\n",
        "    perceptron_defect_model = joblib.load(\"perceptron_defect_model.joblib\")\n",
        "    dnn_defect_model = DefectDNN(input_dim=500, n_labels=7)  # Match Task 2 input dimension and labels\n",
        "    dnn_defect_model.load_state_dict(torch.load(\"dnn_defect_model.pth\"))\n",
        "    dnn_defect_model.eval()\n",
        "    vectorizer = joblib.load(\"vectorizer.joblib\")\n",
        "    scaler = joblib.load(\"scaler.joblib\")\n",
        "\n",
        "    st.success(\"Models and preprocessing objects loaded successfully!\")\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading models or preprocessing objects: {e}\")\n",
        "\n",
        "# Preprocessing functions (match with Task 1 and Task 2)\n",
        "def extract_mfcc(audio_file, n_mfcc=13, max_len=300):\n",
        "    \"\"\"Extract MFCC features from audio file.\"\"\"\n",
        "    y, sr = librosa.load(audio_file, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "    if mfcc.shape[1] < max_len:\n",
        "        mfcc = np.pad(mfcc, ((0, 0), (0, max_len - mfcc.shape[1])), mode='constant')\n",
        "    else:\n",
        "        mfcc = mfcc[:, :max_len]\n",
        "    return mfcc.flatten().reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_defect_features(feature_vector, vectorizer, scaler):\n",
        "    \"\"\"Transform input feature vector for defect prediction.\"\"\"\n",
        "    tfidf_features = vectorizer.transform([feature_vector]).toarray()\n",
        "    scaled_features = scaler.transform(tfidf_features)\n",
        "    return scaled_features\n",
        "\n",
        "# Function to get list of audio files from deepfake_detection_dataset_urdu\n",
        "def get_audio_files():\n",
        "    desktop_path = os.path.expanduser(\"~/Desktop/22F-3625-DS-A-04/deepfake_detection_dataset_urdu\")\n",
        "    audio_files = []\n",
        "    for root, dirs, files in os.walk(desktop_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".wav\"):\n",
        "                audio_files.append(os.path.join(root, file))\n",
        "    return audio_files\n",
        "\n",
        "# Streamlit App\n",
        "st.title(\"Multi-Task Prediction App\")\n",
        "st.write(\"Upload an audio file for deepfake detection or input a feature vector for defect prediction.\")\n",
        "\n",
        "# Sidebar for model selection\n",
        "model_options = [\"Logistic Regression\", \"SVM\", \"Perceptron\", \"DNN\"]\n",
        "selected_model = st.sidebar.selectbox(\"Select Model\", model_options)\n",
        "\n",
        "# Audio Upload Section\n",
        "st.subheader(\"Deepfake Audio Detection\")\n",
        "audio_files = get_audio_files()\n",
        "selected_audio = st.selectbox(\"Select an Audio File from Dataset\", [\"Upload a new file\"] + audio_files)\n",
        "\n",
        "if selected_audio == \"Upload a new file\":\n",
        "    audio_file = st.file_uploader(\"Upload Audio File\", type=[\"wav\", \"mp3\"])\n",
        "else:\n",
        "    audio_file = selected_audio\n",
        "\n",
        "if audio_file is not None:\n",
        "    # Handle both uploaded files and file paths\n",
        "    if isinstance(audio_file, str):\n",
        "        # If it's a file path from the dataset\n",
        "        audio_path = audio_file\n",
        "    else:\n",
        "        # If it's an uploaded file, save it temporarily\n",
        "        audio_path = \"temp_audio.wav\"\n",
        "        with open(audio_path, \"wb\") as f:\n",
        "            f.write(audio_file.getvalue())\n",
        "\n",
        "    mfcc_features = extract_mfcc(audio_path, max_len=300)  # Match Task 1 max_len\n",
        "    scaled_features = audio_scaler.transform(mfcc_features)  # Use Task 1 scaler\n",
        "\n",
        "    if st.button(\"Predict Deepfake\"):\n",
        "        if selected_model == \"Logistic Regression\":\n",
        "            prediction = lr_audio_model.predict_proba(scaled_features)[:, 1][0]\n",
        "        elif selected_model == \"SVM\":\n",
        "            prediction = svm_audio_model.decision_function(scaled_features)[0]  # Approx. probability\n",
        "        elif selected_model == \"Perceptron\":\n",
        "            prediction = (perceptron_audio_model.predict(scaled_features) > 0).astype(int)[0]  # Binary output\n",
        "        else:  # DNN\n",
        "            with torch.no_grad():\n",
        "                input_tensor = torch.tensor(scaled_features, dtype=torch.float32)\n",
        "                prediction = dnn_audio_model(input_tensor).numpy()[0][0]\n",
        "\n",
        "        confidence = prediction if selected_model != \"SVM\" else 1 / (1 + np.exp(-prediction))  # Sigmoid for SVM\n",
        "        label = \"Deepfake\" if confidence > 0.5 else \"Bonafide\"\n",
        "        st.write(f\"Prediction: {label}\")\n",
        "        st.write(f\"Confidence Score: {confidence:.4f}\")\n",
        "\n",
        "    # Clean up temporary file if it was created\n",
        "    if isinstance(audio_file, str) is False and os.path.exists(\"temp_audio.wav\"):\n",
        "        os.remove(\"temp_audio.wav\")\n",
        "\n",
        "# Defect Prediction Section\n",
        "st.subheader(\"Multi-Label Defect Prediction\")\n",
        "feature_input = st.text_area(\"Enter Feature Vector (e.g., text report)\", \"Sample text here\")\n",
        "label_cols = [\"type_blocker\", \"type_regression\", \"type_bug\", \"type_documentation\", \"type_enhancement\", \"type_task\", \"type_dependency_upgrade\"]\n",
        "\n",
        "if st.button(\"Predict Defects\"):\n",
        "    if feature_input:\n",
        "        defect_features = preprocess_defect_features(feature_input, vectorizer, scaler)\n",
        "\n",
        "        if selected_model == \"Logistic Regression\":\n",
        "            # Convert list of arrays to a single numpy array\n",
        "            probas = lr_defect_model.predict_proba(defect_features)\n",
        "            # Ensure each proba is 2D with shape (1, 2)\n",
        "            probas_2d = [proba.reshape(1, -1) if proba.ndim == 1 else proba for proba in probas]\n",
        "            # Extract the probabilities for the positive class (index 1)\n",
        "            predictions = np.array([proba[:, 1] for proba in probas_2d]).T  # Shape: (n_samples, n_labels)\n",
        "        elif selected_model == \"SVM\":\n",
        "            # decision_function returns scores, not probabilities\n",
        "            predictions = svm_defect_model.decision_function(defect_features).T  # Shape: (n_labels, n_samples)\n",
        "        elif selected_model == \"Perceptron\":\n",
        "            predictions = perceptron_defect_model.predict(defect_features).T  # Shape: (n_labels, n_samples)\n",
        "        else:  # DNN\n",
        "            with torch.no_grad():\n",
        "                input_tensor = torch.tensor(defect_features, dtype=torch.float32)\n",
        "                predictions = dnn_defect_model(input_tensor).numpy().T  # Shape: (n_labels, n_samples)\n",
        "\n",
        "        # Convert to binary predictions and confidence scores\n",
        "        binary_predictions = (predictions > 0.5).astype(int)\n",
        "        confidence_scores = np.clip(predictions, 0, 1)  # Ensure scores are between 0 and 1\n",
        "\n",
        "        st.write(\"Predicted Labels:\")\n",
        "        for i, label in enumerate(label_cols):\n",
        "            st.write(f\"{label}: {binary_predictions[i][0]}, Confidence: {confidence_scores[i][0]:.4f}\")\n",
        "    else:\n",
        "        st.write(\"Please enter a feature vector.\")\n",
        "\n",
        "# UI Styling\n",
        "st.sidebar.header(\"Instructions\")\n",
        "st.sidebar.write(\"1. Select a model from the sidebar.\")\n",
        "st.sidebar.write(\"2. Upload an audio file or select from the dataset for deepfake detection.\")\n",
        "st.sidebar.write(\"3. Input a text feature for defect prediction.\")\n",
        "st.sidebar.write(\"4. Click 'Predict' to see results with confidence scores.\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .stButton>button {\n",
        "        background-color: #4CAF50;\n",
        "        color: white;\n",
        "        padding: 10px 20px;\n",
        "    }\n",
        "    .stTextArea {\n",
        "        margin-bottom: 10px;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)"
      ],
      "metadata": {
        "id": "S0ySCdf7fdRX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}